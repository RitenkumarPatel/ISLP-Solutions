{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e492b4d4-55fc-45e4-84a0-617d4697c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as skm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebce005-64dd-478a-babb-00cdca78a764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>No</td>\n",
       "      <td>2197</td>\n",
       "      <td>1515</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1959</td>\n",
       "      <td>1805</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2097</td>\n",
       "      <td>1915</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Yes</td>\n",
       "      <td>10705</td>\n",
       "      <td>2453</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2989</td>\n",
       "      <td>1855</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Private   Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0       Yes   1660    1232     721         23         52         2885   \n",
       "1       Yes   2186    1924     512         16         29         2683   \n",
       "2       Yes   1428    1097     336         22         50         1036   \n",
       "3       Yes    417     349     137         60         89          510   \n",
       "4       Yes    193     146      55         16         44          249   \n",
       "..      ...    ...     ...     ...        ...        ...          ...   \n",
       "772      No   2197    1515     543          4         26         3089   \n",
       "773     Yes   1959    1805     695         24         47         2849   \n",
       "774     Yes   2097    1915     695         34         61         2793   \n",
       "775     Yes  10705    2453    1317         95         99         5217   \n",
       "776     Yes   2989    1855     691         28         63         2988   \n",
       "\n",
       "     P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0            537      7440        3300    450      2200   70        78   \n",
       "1           1227     12280        6450    750      1500   29        30   \n",
       "2             99     11250        3750    400      1165   53        66   \n",
       "3             63     12960        5450    450       875   92        97   \n",
       "4            869      7560        4120    800      1500   76        72   \n",
       "..           ...       ...         ...    ...       ...  ...       ...   \n",
       "772         2029      6797        3900    500      1200   60        60   \n",
       "773         1107     11520        4960    600      1250   73        75   \n",
       "774          166      6900        4200    617       781   67        75   \n",
       "775           83     19840        6510    630      2115   96        96   \n",
       "776         1726      4990        3560    500      1250   75        75   \n",
       "\n",
       "     S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0         18.1           12    7041         60  \n",
       "1         12.2           16   10527         56  \n",
       "2         12.9           30    8735         54  \n",
       "3          7.7           37   19016         59  \n",
       "4         11.9            2   10922         15  \n",
       "..         ...          ...     ...        ...  \n",
       "772       21.0           14    4469         40  \n",
       "773       13.3           31    9189         83  \n",
       "774       14.4           20    8323         49  \n",
       "775        5.8           49   40386         99  \n",
       "776       18.1           28    4509         99  \n",
       "\n",
       "[777 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(\"College\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe8ebe1-055a-4ab5-9ec9-91eda29ccf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Enroll  Top10perc  Top25perc  F.Undergrad  P.Undergrad  Outstate  \\\n",
       "0       721         23         52         2885          537      7440   \n",
       "1       512         16         29         2683         1227     12280   \n",
       "2       336         22         50         1036           99     11250   \n",
       "3       137         60         89          510           63     12960   \n",
       "4        55         16         44          249          869      7560   \n",
       "..      ...        ...        ...          ...          ...       ...   \n",
       "772     543          4         26         3089         2029      6797   \n",
       "773     695         24         47         2849         1107     11520   \n",
       "774     695         34         61         2793          166      6900   \n",
       "775    1317         95         99         5217           83     19840   \n",
       "776     691         28         63         2988         1726      4990   \n",
       "\n",
       "     Room.Board  Books  Personal  PhD  Terminal  S.F.Ratio  perc.alumni  \\\n",
       "0          3300    450      2200   70        78       18.1           12   \n",
       "1          6450    750      1500   29        30       12.2           16   \n",
       "2          3750    400      1165   53        66       12.9           30   \n",
       "3          5450    450       875   92        97        7.7           37   \n",
       "4          4120    800      1500   76        72       11.9            2   \n",
       "..          ...    ...       ...  ...       ...        ...          ...   \n",
       "772        3900    500      1200   60        60       21.0           14   \n",
       "773        4960    600      1250   73        75       13.3           31   \n",
       "774        4200    617       781   67        75       14.4           20   \n",
       "775        6510    630      2115   96        96        5.8           49   \n",
       "776        3560    500      1250   75        75       18.1           28   \n",
       "\n",
       "     Expend  Grad.Rate  \n",
       "0      7041         60  \n",
       "1     10527         56  \n",
       "2      8735         54  \n",
       "3     19016         59  \n",
       "4     10922         15  \n",
       "..      ...        ...  \n",
       "772    4469         40  \n",
       "773    9189         83  \n",
       "774    8323         49  \n",
       "775   40386         99  \n",
       "776    4509         99  \n",
       "\n",
       "[777 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop private var since it's categorical (won't work well for ridge and lasso)\n",
    "# Dropping private and apps\n",
    "X = df.iloc[:,3:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2123adc-a997-4534-abd1-6d5ca30edf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Apps']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7aaf97-3793-4639-95b6-0d14885d40c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Apps</td>       <th>  R-squared (uncentered):</th>      <td>   0.856</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.852</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   224.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 05 Jun 2024</td> <th>  Prob (F-statistic):</th>          <td>9.87e-227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:31:41</td>     <th>  Log-Likelihood:    </th>          <td> -5231.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   582</td>      <th>  AIC:               </th>          <td>1.049e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   567</td>      <th>  BIC:               </th>          <td>1.056e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Enroll</th>      <td>    2.8263</td> <td>    0.340</td> <td>    8.317</td> <td> 0.000</td> <td>    2.159</td> <td>    3.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Top10perc</th>   <td>   28.6049</td> <td>   11.569</td> <td>    2.473</td> <td> 0.014</td> <td>    5.881</td> <td>   51.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Top25perc</th>   <td>   -2.4184</td> <td>    9.416</td> <td>   -0.257</td> <td> 0.797</td> <td>  -20.913</td> <td>   16.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F.Undergrad</th> <td>    0.1464</td> <td>    0.069</td> <td>    2.125</td> <td> 0.034</td> <td>    0.011</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P.Undergrad</th> <td>   -0.0025</td> <td>    0.065</td> <td>   -0.038</td> <td> 0.970</td> <td>   -0.130</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outstate</th>    <td>    0.0083</td> <td>    0.038</td> <td>    0.215</td> <td> 0.830</td> <td>   -0.067</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Room.Board</th>  <td>    0.3495</td> <td>    0.103</td> <td>    3.407</td> <td> 0.001</td> <td>    0.148</td> <td>    0.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Books</th>       <td>   -0.4362</td> <td>    0.479</td> <td>   -0.910</td> <td> 0.363</td> <td>   -1.377</td> <td>    0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Personal</th>    <td>   -0.3451</td> <td>    0.126</td> <td>   -2.741</td> <td> 0.006</td> <td>   -0.592</td> <td>   -0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PhD</th>         <td>   -0.5654</td> <td>   10.027</td> <td>   -0.056</td> <td> 0.955</td> <td>  -20.261</td> <td>   19.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Terminal</th>    <td>  -16.6496</td> <td>   10.523</td> <td>   -1.582</td> <td> 0.114</td> <td>  -37.319</td> <td>    4.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S.F.Ratio</th>   <td>  -31.4568</td> <td>   21.457</td> <td>   -1.466</td> <td> 0.143</td> <td>  -73.601</td> <td>   10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perc.alumni</th> <td>  -33.8881</td> <td>    8.953</td> <td>   -3.785</td> <td> 0.000</td> <td>  -51.473</td> <td>  -16.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Expend</th>      <td>    0.0619</td> <td>    0.025</td> <td>    2.438</td> <td> 0.015</td> <td>    0.012</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grad.Rate</th>   <td>   11.2932</td> <td>    6.217</td> <td>    1.816</td> <td> 0.070</td> <td>   -0.918</td> <td>   23.505</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>862.941</td> <th>  Durbin-Watson:     </th>  <td>   1.992</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>406538.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 7.813</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>131.531</td> <th>  Cond. No.          </th>  <td>4.46e+03</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 4.46e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       Apps       & \\textbf{  R-squared (uncentered):}      &     0.856   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.852   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     224.0   \\\\\n",
       "\\textbf{Date:}             & Wed, 05 Jun 2024 & \\textbf{  Prob (F-statistic):}          & 9.87e-227   \\\\\n",
       "\\textbf{Time:}             &     12:31:41     & \\textbf{  Log-Likelihood:    }          &   -5231.1   \\\\\n",
       "\\textbf{No. Observations:} &         582      & \\textbf{  AIC:               }          & 1.049e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &         567      & \\textbf{  BIC:               }          & 1.056e+04   \\\\\n",
       "\\textbf{Df Model:}         &          15      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Enroll}      &       2.8263  &        0.340     &     8.317  &         0.000        &        2.159    &        3.494     \\\\\n",
       "\\textbf{Top10perc}   &      28.6049  &       11.569     &     2.473  &         0.014        &        5.881    &       51.328     \\\\\n",
       "\\textbf{Top25perc}   &      -2.4184  &        9.416     &    -0.257  &         0.797        &      -20.913    &       16.076     \\\\\n",
       "\\textbf{F.Undergrad} &       0.1464  &        0.069     &     2.125  &         0.034        &        0.011    &        0.282     \\\\\n",
       "\\textbf{P.Undergrad} &      -0.0025  &        0.065     &    -0.038  &         0.970        &       -0.130    &        0.125     \\\\\n",
       "\\textbf{Outstate}    &       0.0083  &        0.038     &     0.215  &         0.830        &       -0.067    &        0.084     \\\\\n",
       "\\textbf{Room.Board}  &       0.3495  &        0.103     &     3.407  &         0.001        &        0.148    &        0.551     \\\\\n",
       "\\textbf{Books}       &      -0.4362  &        0.479     &    -0.910  &         0.363        &       -1.377    &        0.505     \\\\\n",
       "\\textbf{Personal}    &      -0.3451  &        0.126     &    -2.741  &         0.006        &       -0.592    &       -0.098     \\\\\n",
       "\\textbf{PhD}         &      -0.5654  &       10.027     &    -0.056  &         0.955        &      -20.261    &       19.130     \\\\\n",
       "\\textbf{Terminal}    &     -16.6496  &       10.523     &    -1.582  &         0.114        &      -37.319    &        4.020     \\\\\n",
       "\\textbf{S.F.Ratio}   &     -31.4568  &       21.457     &    -1.466  &         0.143        &      -73.601    &       10.688     \\\\\n",
       "\\textbf{perc.alumni} &     -33.8881  &        8.953     &    -3.785  &         0.000        &      -51.473    &      -16.303     \\\\\n",
       "\\textbf{Expend}      &       0.0619  &        0.025     &     2.438  &         0.015        &        0.012    &        0.112     \\\\\n",
       "\\textbf{Grad.Rate}   &      11.2932  &        6.217     &     1.816  &         0.070        &       -0.918    &       23.505     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 862.941 & \\textbf{  Durbin-Watson:     } &     1.992   \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 406538.104  \\\\\n",
       "\\textbf{Skew:}          &   7.813 & \\textbf{  Prob(JB):          } &      0.00   \\\\\n",
       "\\textbf{Kurtosis:}      & 131.531 & \\textbf{  Cond. No.          } &  4.46e+03   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [3] The condition number is large, 4.46e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                   Apps   R-squared (uncentered):                   0.856\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.852\n",
       "Method:                 Least Squares   F-statistic:                              224.0\n",
       "Date:                Wed, 05 Jun 2024   Prob (F-statistic):                   9.87e-227\n",
       "Time:                        12:31:41   Log-Likelihood:                         -5231.1\n",
       "No. Observations:                 582   AIC:                                  1.049e+04\n",
       "Df Residuals:                     567   BIC:                                  1.056e+04\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Enroll          2.8263      0.340      8.317      0.000       2.159       3.494\n",
       "Top10perc      28.6049     11.569      2.473      0.014       5.881      51.328\n",
       "Top25perc      -2.4184      9.416     -0.257      0.797     -20.913      16.076\n",
       "F.Undergrad     0.1464      0.069      2.125      0.034       0.011       0.282\n",
       "P.Undergrad    -0.0025      0.065     -0.038      0.970      -0.130       0.125\n",
       "Outstate        0.0083      0.038      0.215      0.830      -0.067       0.084\n",
       "Room.Board      0.3495      0.103      3.407      0.001       0.148       0.551\n",
       "Books          -0.4362      0.479     -0.910      0.363      -1.377       0.505\n",
       "Personal       -0.3451      0.126     -2.741      0.006      -0.592      -0.098\n",
       "PhD            -0.5654     10.027     -0.056      0.955     -20.261      19.130\n",
       "Terminal      -16.6496     10.523     -1.582      0.114     -37.319       4.020\n",
       "S.F.Ratio     -31.4568     21.457     -1.466      0.143     -73.601      10.688\n",
       "perc.alumni   -33.8881      8.953     -3.785      0.000     -51.473     -16.303\n",
       "Expend          0.0619      0.025      2.438      0.015       0.012       0.112\n",
       "Grad.Rate      11.2932      6.217      1.816      0.070      -0.918      23.505\n",
       "==============================================================================\n",
       "Omnibus:                      862.941   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           406538.104\n",
       "Skew:                           7.813   Prob(JB):                         0.00\n",
       "Kurtosis:                     131.531   Cond. No.                     4.46e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 4.46e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinary Least squares\n",
    "# Adj Rsquared is 0.852, multiple variables have a high p-val\n",
    "results = sm.OLS(y_train,X_train).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f81749-15ac-4725-81fc-963c715d9551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051258.5777322883"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = results.predict(X_test)\n",
    "score = ((y_test - pred)**2).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2e5841f-ebf0-4a2f-b7ad-2b9c43ef9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "399bf52f-6316-43e1-8575-e361816ec113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeCV(alphas=array([  0.1,   0.2,   0.3,   0.4,   0.5,   0.6,   0.7,   0.8,   0.9,\n",
       "         1. ,   1.1,   1.2,   1.3,   1.4,   1.5,   1.6,   1.7,   1.8,\n",
       "         1.9,   2. ,   2.1,   2.2,   2.3,   2.4,   2.5,   2.6,   2.7,\n",
       "         2.8,   2.9,   3. ,   3.1,   3.2,   3.3,   3.4,   3.5,   3.6,\n",
       "         3.7,   3.8,   3.9,   4. ,   4.1,   4.2,   4.3,   4.4,   4.5,\n",
       "         4.6,   4.7,   4.8,   4.9,   5. ,   5.1,   5.2,   5.3,   5.4,\n",
       "         5.5,   5.6,   5.7,   5.8,   5.9,   6. ,   6.1,   6.2,   6.3,\n",
       "         6.4,   6.5,   6.6,   6.7,   6.8,   6.9,   7. ,   7.1,   7.2,\n",
       "         7.3,   7.4,   7.5,   7.6,   7.7,   7.8,   7.9,   8. ,   8.1,\n",
       "         8.2,   8.3,   8.4,...\n",
       "        92.8,  92.9,  93. ,  93.1,  93.2,  93.3,  93.4,  93.5,  93.6,\n",
       "        93.7,  93.8,  93.9,  94. ,  94.1,  94.2,  94.3,  94.4,  94.5,\n",
       "        94.6,  94.7,  94.8,  94.9,  95. ,  95.1,  95.2,  95.3,  95.4,\n",
       "        95.5,  95.6,  95.7,  95.8,  95.9,  96. ,  96.1,  96.2,  96.3,\n",
       "        96.4,  96.5,  96.6,  96.7,  96.8,  96.9,  97. ,  97.1,  97.2,\n",
       "        97.3,  97.4,  97.5,  97.6,  97.7,  97.8,  97.9,  98. ,  98.1,\n",
       "        98.2,  98.3,  98.4,  98.5,  98.6,  98.7,  98.8,  98.9,  99. ,\n",
       "        99.1,  99.2,  99.3,  99.4,  99.5,  99.6,  99.7,  99.8,  99.9,\n",
       "       100. ]),\n",
       "        cv=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV(alphas=array([  0.1,   0.2,   0.3,   0.4,   0.5,   0.6,   0.7,   0.8,   0.9,\n",
       "         1. ,   1.1,   1.2,   1.3,   1.4,   1.5,   1.6,   1.7,   1.8,\n",
       "         1.9,   2. ,   2.1,   2.2,   2.3,   2.4,   2.5,   2.6,   2.7,\n",
       "         2.8,   2.9,   3. ,   3.1,   3.2,   3.3,   3.4,   3.5,   3.6,\n",
       "         3.7,   3.8,   3.9,   4. ,   4.1,   4.2,   4.3,   4.4,   4.5,\n",
       "         4.6,   4.7,   4.8,   4.9,   5. ,   5.1,   5.2,   5.3,   5.4,\n",
       "         5.5,   5.6,   5.7,   5.8,   5.9,   6. ,   6.1,   6.2,   6.3,\n",
       "         6.4,   6.5,   6.6,   6.7,   6.8,   6.9,   7. ,   7.1,   7.2,\n",
       "         7.3,   7.4,   7.5,   7.6,   7.7,   7.8,   7.9,   8. ,   8.1,\n",
       "         8.2,   8.3,   8.4,...\n",
       "        92.8,  92.9,  93. ,  93.1,  93.2,  93.3,  93.4,  93.5,  93.6,\n",
       "        93.7,  93.8,  93.9,  94. ,  94.1,  94.2,  94.3,  94.4,  94.5,\n",
       "        94.6,  94.7,  94.8,  94.9,  95. ,  95.1,  95.2,  95.3,  95.4,\n",
       "        95.5,  95.6,  95.7,  95.8,  95.9,  96. ,  96.1,  96.2,  96.3,\n",
       "        96.4,  96.5,  96.6,  96.7,  96.8,  96.9,  97. ,  97.1,  97.2,\n",
       "        97.3,  97.4,  97.5,  97.6,  97.7,  97.8,  97.9,  98. ,  98.1,\n",
       "        98.2,  98.3,  98.4,  98.5,  98.6,  98.7,  98.8,  98.9,  99. ,\n",
       "        99.1,  99.2,  99.3,  99.4,  99.5,  99.6,  99.7,  99.8,  99.9,\n",
       "       100. ]),\n",
       "        cv=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeCV(alphas=array([  0.1,   0.2,   0.3,   0.4,   0.5,   0.6,   0.7,   0.8,   0.9,\n",
       "         1. ,   1.1,   1.2,   1.3,   1.4,   1.5,   1.6,   1.7,   1.8,\n",
       "         1.9,   2. ,   2.1,   2.2,   2.3,   2.4,   2.5,   2.6,   2.7,\n",
       "         2.8,   2.9,   3. ,   3.1,   3.2,   3.3,   3.4,   3.5,   3.6,\n",
       "         3.7,   3.8,   3.9,   4. ,   4.1,   4.2,   4.3,   4.4,   4.5,\n",
       "         4.6,   4.7,   4.8,   4.9,   5. ,   5.1,   5.2,   5.3,   5.4,\n",
       "         5.5,   5.6,   5.7,   5.8,   5.9,   6. ,   6.1,   6.2,   6.3,\n",
       "         6.4,   6.5,   6.6,   6.7,   6.8,   6.9,   7. ,   7.1,   7.2,\n",
       "         7.3,   7.4,   7.5,   7.6,   7.7,   7.8,   7.9,   8. ,   8.1,\n",
       "         8.2,   8.3,   8.4,...\n",
       "        92.8,  92.9,  93. ,  93.1,  93.2,  93.3,  93.4,  93.5,  93.6,\n",
       "        93.7,  93.8,  93.9,  94. ,  94.1,  94.2,  94.3,  94.4,  94.5,\n",
       "        94.6,  94.7,  94.8,  94.9,  95. ,  95.1,  95.2,  95.3,  95.4,\n",
       "        95.5,  95.6,  95.7,  95.8,  95.9,  96. ,  96.1,  96.2,  96.3,\n",
       "        96.4,  96.5,  96.6,  96.7,  96.8,  96.9,  97. ,  97.1,  97.2,\n",
       "        97.3,  97.4,  97.5,  97.6,  97.7,  97.8,  97.9,  98. ,  98.1,\n",
       "        98.2,  98.3,  98.4,  98.5,  98.6,  98.7,  98.8,  98.9,  99. ,\n",
       "        99.1,  99.2,  99.3,  99.4,  99.5,  99.6,  99.7,  99.8,  99.9,\n",
       "       100. ]),\n",
       "        cv=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv = RidgeCV(alphas=np.linspace(0.1, 100, 1000), cv=10)\n",
    "rcv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3e3ce8a-a8bd-4b4a-b042-189eb3ab0c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8016260052257205"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77decf88-6066-4e51-ab18-80bb46803fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2033100.6020789458"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((rcv.predict(X_test_scaled)-y_test)**2).mean()\n",
    "# MSE For ridge isn't much better than for OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94a673fc-251a-4b8e-b321-f156576cee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085798654746663"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcv = LassoCV(alphas=np.linspace(0.1,100,1000), cv=10)\n",
    "lcv.fit(X_train_scaled, y_train)\n",
    "lcv.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbefa906-ea11-4bc4-a72d-5fa77895bc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1961831.6967217114"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((lcv.predict(X_test_scaled)-y_test)**2).mean()\n",
    "# MSE for lasso is a little better than OLS and ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "423aa9be-7aad-4e41-9da1-f5f6265fd185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2757.53402951,  289.89144306,   56.3913505 ,  535.10303993,\n",
       "         -0.        ,    0.        ,  444.04650551,    0.        ,\n",
       "        -52.39735162,   -0.        ,   -0.        ,   62.49785743,\n",
       "       -280.56096451,  352.17382641,  282.1391372 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dbde654-c24d-4a45-8ac7-4ec1dd7fdc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04797823, 0.64631343])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# PCR\n",
    "pca = PCA(n_components=2)\n",
    "linreg = skl.LinearRegression()\n",
    "pipe = Pipeline([('pca',pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X,y)\n",
    "pipe.named_steps['linreg'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0924f8a-5f72-4ac2-870f-64c0c7146697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 428.74164613, 1632.26879212])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing the data first\n",
    "pipe = Pipeline([('scaler',scaler),\n",
    "                 ('pca',pca),\n",
    "                 ('linreg', linreg)])\n",
    "pipe.fit(X,y)\n",
    "pipe.named_steps['linreg'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "659511df-181e-47e2-bb79-b64642b2cbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=30, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;pca&#x27;, PCA(n_components=2)),\n",
       "                                       (&#x27;linreg&#x27;, LinearRegression())]),\n",
       "             param_grid={&#x27;pca__n_components&#x27;: range(1, 15)},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=30, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;pca&#x27;, PCA(n_components=2)),\n",
       "                                       (&#x27;linreg&#x27;, LinearRegression())]),\n",
       "             param_grid={&#x27;pca__n_components&#x27;: range(1, 15)},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=2)),\n",
       "                (&#x27;linreg&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=30, random_state=0, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('pca', PCA(n_components=2)),\n",
       "                                       ('linreg', LinearRegression())]),\n",
       "             param_grid={'pca__n_components': range(1, 15)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 30\n",
    "kfold = skm.KFold(K,\n",
    "                  random_state=0,\n",
    "                  shuffle=True)\n",
    "# Fixing params to vary the components\n",
    "param_grid = {'pca__n_components': range(1,15)}\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5041fef-dbe4-4f66-a9c2-4e90ded0746d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3442731.897412277"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-grid.cv_results_['mean_test_score']).min()\n",
    "# This was the worst by far, maybe I did something wrong ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cbea2fb6-13b5-4668-919f-f61b08f9a387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(-grid.cv_results_['mean_test_score'])\n",
    "# PCR did best with 9 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "242cb8f3-db57-4e21-9931-a74641966341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PLSRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" checked><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PLSRegression</label><div class=\"sk-toggleable__content\"><pre>PLSRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PLSRegression()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "# Partial Least Squares\n",
    "pls = PLSRegression(n_components=2,\n",
    "                    scale=True)\n",
    "pls.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab87118d-16ad-4b9e-afbf-7180877e34e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "120 fits failed out of a total of 570.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cross_decomposition/_pls.py\", line 640, in fit\n",
      "    super().fit(X, Y)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cross_decomposition/_pls.py\", line 253, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 15. Got 16 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cross_decomposition/_pls.py\", line 640, in fit\n",
      "    super().fit(X, Y)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cross_decomposition/_pls.py\", line 253, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 15. Got 17 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cross_decomposition/_pls.py\", line 640, in fit\n",
      "    super().fit(X, Y)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cross_decomposition/_pls.py\", line 253, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 15. Got 18 instead. Reduce `n_components`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cross_decomposition/_pls.py\", line 640, in fit\n",
      "    super().fit(X, Y)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cross_decomposition/_pls.py\", line 253, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `n_components` upper bound is 15. Got 19 instead. Reduce `n_components`.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [-5123818.51443591 -4349937.26926193 -3491120.09281443 -3446685.36913348\n",
      " -3447539.33816217 -3456615.04199888 -3452595.53319417 -3451625.37074494\n",
      " -3440591.80456175 -3433444.65590729 -3433786.05167428 -3434333.70172785\n",
      " -3434045.15011541 -3434139.20337603 -3434176.44557431               nan\n",
      "               nan               nan               nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=30, random_state=0, shuffle=True),\n",
       "             estimator=PLSRegression(),\n",
       "             param_grid={&#x27;n_components&#x27;: range(1, 20)},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=30, random_state=0, shuffle=True),\n",
       "             estimator=PLSRegression(),\n",
       "             param_grid={&#x27;n_components&#x27;: range(1, 20)},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: PLSRegression</label><div class=\"sk-toggleable__content\"><pre>PLSRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PLSRegression</label><div class=\"sk-toggleable__content\"><pre>PLSRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=30, random_state=0, shuffle=True),\n",
       "             estimator=PLSRegression(),\n",
       "             param_grid={'n_components': range(1, 20)},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use CV to choose num of components\n",
    "param_grid = {'n_components': range(1,20)}\n",
    "grid = skm.GridSearchCV(pls,\n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73978b5-1be2-4a9d-860b-7ca0dd4be79f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
